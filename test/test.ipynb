{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenPose 연습\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방법 1. MPI\n",
    "- 출력 관절 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 ID :  44 , H :  83 , W :  81\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# MPII에서 각 파트 번호, 선으로 연결될 POSE_PAIRS\n",
    "BODY_PARTS = { \"Head\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "                \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "                \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"Chest\": 14,\n",
    "                \"Background\": 15 }\n",
    "\n",
    "POSE_PAIRS = [ [\"Head\", \"Neck\"], [\"Neck\", \"RShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "                [\"RElbow\", \"RWrist\"], [\"Neck\", \"LShoulder\"], [\"LShoulder\", \"LElbow\"],\n",
    "                [\"LElbow\", \"LWrist\"], [\"Neck\", \"Chest\"], [\"Chest\", \"RHip\"], [\"RHip\", \"RKnee\"],\n",
    "                [\"RKnee\", \"RAnkle\"], [\"Chest\", \"LHip\"], [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"] ]\n",
    "    \n",
    "# 각 파일 path\n",
    "protoFile = 'mpii/pose_deploy_linevec_faster_4_stages.prototxt'\n",
    "weightsFile = 'mpii/pose_iter_160000.caffemodel'\n",
    " \n",
    "# 위의 path에 있는 network 불러오기\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "\n",
    "# 이미지 읽어오기\n",
    "image = cv2.imread(\"image.JPG\")\n",
    "\n",
    "# frame.shape = 불러온 이미지에서 height, width, color 받아옴\n",
    "imageHeight, imageWidth, _ = image.shape\n",
    " \n",
    "# network에 넣기위해 전처리\n",
    "inpBlob = cv2.dnn.blobFromImage(image, 1.0 / 255, (imageWidth, imageHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    " \n",
    "# network에 넣어주기\n",
    "net.setInput(inpBlob)\n",
    "\n",
    "# 결과 받아오기\n",
    "output = net.forward()\n",
    "\n",
    "# output.shape[0] = 이미지 ID, [1] = 출력 맵의 높이, [2] = 너비\n",
    "H = output.shape[2]\n",
    "W = output.shape[3]\n",
    "print(\"이미지 ID : \", len(output[0]), \", H : \", output.shape[2], \", W : \",output.shape[3]) # 이미지 ID\n",
    "\n",
    "# 키포인트 검출시 이미지에 그려줌\n",
    "points = []\n",
    "for i in range(0,15):\n",
    "    # 해당 신체부위 신뢰도 얻음.\n",
    "    probMap = output[0, i, :, :]\n",
    " \n",
    "    # global 최대값 찾기\n",
    "    minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "    # 원래 이미지에 맞게 점 위치 변경\n",
    "    x = (imageWidth * point[0]) / W\n",
    "    y = (imageHeight * point[1]) / H\n",
    "\n",
    "    # 키포인트 검출한 결과가 0.1보다 크면(검출한곳이 위 BODY_PARTS랑 맞는 부위면) points에 추가, 검출했는데 부위가 없으면 None으로    \n",
    "    if prob > 0.1 :    \n",
    "        cv2.circle(image, (int(x), int(y)), 3, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)       # circle(그릴곳, 원의 중심, 반지름, 색)\n",
    "        cv2.putText(image, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "        points.append((int(x), int(y)))\n",
    "    else :\n",
    "        points.append(None)\n",
    "\n",
    "# cv2.imshow(\"Output-Keypoints\",image)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# 이미지 복사\n",
    "imageCopy = image\n",
    "\n",
    "# 각 POSE_PAIRS별로 선 그어줌 (머리 - 목, 목 - 왼쪽어깨, ...)\n",
    "for pair in POSE_PAIRS:\n",
    "    partA = pair[0]             # Head\n",
    "    partA = BODY_PARTS[partA]   # 0\n",
    "    partB = pair[1]             # Neck\n",
    "    partB = BODY_PARTS[partB]   # 1\n",
    "    \n",
    "    #print(partA,\" 와 \", partB, \" 연결\\n\")\n",
    "    if points[partA] and points[partB]:\n",
    "        cv2.line(imageCopy, points[partA], points[partB], (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Output-Keypoints\",imageCopy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m net\u001b[39m.\u001b[39msetInput(inpBlob)\n\u001b[0;32m     63\u001b[0m \u001b[39m# 결과 받아오기\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m output \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mforward()\n\u001b[0;32m     67\u001b[0m \u001b[39m# 키포인트 검출시 이미지에 그려줌\u001b[39;00m\n\u001b[0;32m     68\u001b[0m points \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 웹캠\n",
    "\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "# MPII에서 각 파트 번호, 선으로 연결될 POSE_PAIRS\n",
    "BODY_PARTS = { \"Head\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "                \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "                \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"Chest\": 14,\n",
    "                \"Background\": 15 }\n",
    "\n",
    "POSE_PAIRS = [ [\"Head\", \"Neck\"], [\"Neck\", \"RShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "                [\"RElbow\", \"RWrist\"], [\"Neck\", \"LShoulder\"], [\"LShoulder\", \"LElbow\"],\n",
    "                [\"LElbow\", \"LWrist\"], [\"Neck\", \"Chest\"], [\"Chest\", \"RHip\"], [\"RHip\", \"RKnee\"],\n",
    "                [\"RKnee\", \"RAnkle\"], [\"Chest\", \"LHip\"], [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"] ]\n",
    "    \n",
    "# 각 파일 path\n",
    "#BASE_DIR=Path(__file__).resolve().parent\n",
    "protoFile = 'mpii/pose_deploy_linevec_faster_4_stages.prototxt'\n",
    "weightsFile = 'mpii/pose_iter_160000.caffemodel'\n",
    " \n",
    "# 위의 path에 있는 network 모델 불러오기\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "\n",
    "#쿠다 사용 안하면 밑에 이미지 크기를 줄이는게 나을 것이다\n",
    "# net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA) #벡엔드로 쿠다를 사용하여 속도향상을 꾀한다\n",
    "# net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA) # 쿠다 디바이스에 계산 요청\n",
    "\n",
    "\n",
    "###카메라랑 연결...?\n",
    "capture = cv2.VideoCapture(0) #카메라 정보 받아옴\n",
    "# capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640) #카메라 속성 설정\n",
    "# capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) # width:너비, height: 높이\n",
    "\n",
    "inputWidth=320;\n",
    "inputHeight=240;\n",
    "inputScale=1.0/255;\n",
    "\n",
    " \n",
    "#반복문을 통해 카메라에서 프레임을 지속적으로 받아옴\n",
    "while cv2.waitKey(1) <0:  #아무 키나 누르면 끝난다.\n",
    "    #웹캠으로부터 영상 가져옴\n",
    "    hasFrame, frame = capture.read()  \n",
    "    \n",
    "    #영상이 커서 느리면 사이즈를 줄이자\n",
    "    #frame=cv2.resize(frame,dsize=(320,240),interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    #웹캠으로부터 영상을 가져올 수 없으면 웹캠 중지\n",
    "    if not hasFrame:\n",
    "        cv2.waitKey()\n",
    "        break\n",
    "    \n",
    "    # \n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    \n",
    "    inpBlob = cv2.dnn.blobFromImage(frame, inputScale, (inputWidth, inputHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "    \n",
    "    imgb=cv2.dnn.imagesFromBlob(inpBlob)\n",
    "    #cv2.imshow(\"motion\",(imgb[0]*255.0).astype(np.uint8))\n",
    "    \n",
    "    # network에 넣어주기\n",
    "    net.setInput(inpBlob)\n",
    "\n",
    "    # 결과 받아오기\n",
    "    output = net.forward()\n",
    "\n",
    "    # 키포인트 검출시 이미지에 그려줌\n",
    "    points = []\n",
    "    for i in range(0,15):\n",
    "        # 해당 신체부위 신뢰도 얻음.\n",
    "        probMap = output[0, i, :, :]\n",
    "    \n",
    "        # global 최대값 찾기\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "        # 원래 이미지에 맞게 점 위치 변경\n",
    "        x = (frameWidth * point[0]) / output.shape[3]\n",
    "        y = (frameHeight * point[1]) / output.shape[2]\n",
    "\n",
    "        # 키포인트 검출한 결과가 0.1보다 크면(검출한곳이 위 BODY_PARTS랑 맞는 부위면) points에 추가, 검출했는데 부위가 없으면 None으로    \n",
    "        if prob > 0.1 :    \n",
    "            cv2.circle(frame, (int(x), int(y)), 3, (0, 255, 255), thickness=-1, lineType=cv2.FILLED) # circle(그릴곳, 원의 중심, 반지름, 색)\n",
    "            cv2.putText(frame, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "            points.append((int(x), int(y)))\n",
    "        else :\n",
    "            points.append(None)\n",
    "\n",
    "    # 각 POSE_PAIRS별로 선 그어줌 (머리 - 목, 목 - 왼쪽어깨, ...)\n",
    "    for pair in POSE_PAIRS:\n",
    "        partA = pair[0]             # Head\n",
    "        partA = BODY_PARTS[partA]   # 0\n",
    "        partB = pair[1]             # Neck\n",
    "        partB = BODY_PARTS[partB]   # 1\n",
    "        \n",
    "        #partA와 partB 사이에 선을 그어줌 (cv2.line)\n",
    "        if points[partA] and points[partB]:\n",
    "            cv2.line(frame, points[partA], points[partB], (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"Output-Keypoints\",frame)\n",
    " \n",
    "capture.release()  #카메라 장치에서 받아온 메모리 해제\n",
    "cv2.destroyAllWindows() #모든 윈도우 창 닫음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방법 2. coco\n",
    "- 출력 관절 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# 모델 & 설정 파일\n",
    "model = 'coco/pose_iter_440000.caffemodel'\n",
    "#여러명도 검출할 능력이 있는 모델이나, 후처리가 좀 복잡해서 일단 생략한다.\n",
    "config = 'coco/pose_deploy_linevec.prototxt'\n",
    "\n",
    "# 포즈 점 개수, 점 연결 개수, 연결 점 번호 쌍\n",
    "nparts = 18 #점이 18개니\n",
    "npairs = 17  #잇는 선은 -1인 17개다.\n",
    "pose_pairs = [(1, 2), (2, 3), (3, 4),  # 왼팔\n",
    "              (1, 5), (5, 6), (6, 7),  # 오른팔\n",
    "              (1, 8), (8, 9), (9, 10),  # 왼쪽다리\n",
    "              (1, 11), (11, 12), (12, 13),  # 오른쪽다리\n",
    "              (1, 0), (0, 14), (14, 16), (0, 15), (15, 17)]  # 얼굴\n",
    "\n",
    "# 테스트 이미지 파일\n",
    "img_files = ['image.JPG', 'image2.JPG']\n",
    "\n",
    "# 네트워크 생성 #네트워크 객체 생성\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if net.empty():\n",
    "    print('Net open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "#이미지 한장씩 불러와서\n",
    "\n",
    "for f in img_files:\n",
    "    img = cv2.imread(f)\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    # 블롭 생성 & 추론 함수 호출한다.\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255., (368, 368))\n",
    "    #사이즈와 스케일만 지정하면 스콥,스왑은 그냥 디폴트값쓰면 된다.\n",
    "    net.setInput(blob)\n",
    "    out = net.forward()  # out.shape=(1, 57, 46, 46)\n",
    "    #out이라는 블럽인 ndarray의 shape이 1,57,46,46으로 되며 57다 안쓰고 우리는 앞의 18개만 쓸것이다.\n",
    "    h, w = img.shape[:2]\n",
    "    # 검출된 점 추출\n",
    "    points = []\n",
    "    for i in range(nparts):\n",
    "        #18개의 점에 대해서만 for loop를 돌면서\n",
    "        heatMap = out[0, i, :, :]\n",
    "        #out에서,0은 더미 i가 17까지 돌고, 이게 히트맵으로 받으며 이건 46 by 46의 float형이다.\n",
    "\n",
    "        _, conf, _, point = cv2.minMaxLoc(heatMap)\n",
    "        #heatmap은 최대값 위치를 찾아서 point에, 최대값 자체는 conf에 저장한다. 최소값은 안쓰니 밑줄 !, point는 46 by 46 에서의 위치인데, 입력영상에서의 위치를 찾는 것이니,!! 여기서 전체 w h에서의 위치를 비례식으로 찾는다.\n",
    "        x = int(w * point[0] / out.shape[3])\n",
    "        y = int(h * point[1] / out.shape[2])\n",
    "\n",
    "        points.append((x, y) if conf > 0.1 else None)  # heat map threshold=0.1\n",
    "\n",
    "        #confidence가 0.1보다 큰것만 담는다. 0.1이하는 에러일수있으니, ! \n",
    "    # 검출 결과 영상 만들기\n",
    "\n",
    "    for pair in pose_pairs:\n",
    "        p1 = points[pair[0]]\n",
    "        p2 = points[pair[1]]\n",
    "        #점이 시작과 끝을 p1,p2로 받는다.\n",
    "        if p1 is None or p2 is None:\n",
    "            continue\n",
    "            #만약 p1이나 p2를 검출못하면 무시한다.\n",
    "        cv2.line(img, p1, p2, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "        cv2.circle(img, p1, 4, (0, 0, 255), -1, cv2.LINE_AA)\n",
    "        cv2.circle(img, p2, 4, (0, 0, 255), -1, cv2.LINE_AA)\n",
    "        #두점을 잇는 두꼐 3의 직선 그리고 빨간 원을 그린다.\n",
    "\n",
    "    # 추론 시간 출력\n",
    "    t, _ = net.getPerfProfile()\n",
    "    label = 'Inference time: %.2f ms' % (t * 1000.0 / cv2.getTickFrequency())\n",
    "    cv2.putText(img, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.7, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "    cv2.imshow('img', img)\n",
    "    cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
